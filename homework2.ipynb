{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446e5643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id                                               text author\n",
      "18893  id00577  Among the others he saw Professor Warren Rice ...    HPL\n",
      "12428  id02109  I saw that two of its iron angles were now acu...    EAP\n",
      "17358  id25095  Cut loose, then, in high spirits, and rose gen...    EAP\n",
      "710    id02126  But, if the contest have proceeded thus far, i...    EAP\n",
      "16585  id14188  My reply was ready; a reproach I deemed calcul...    MWS\n",
      "...        ...                                                ...    ...\n",
      "7389   id14126  At these times he would shew a sardonic humour...    HPL\n",
      "2095   id22930  'Why, sir, there beant an o in the office, nei...    EAP\n",
      "17885  id00289  Would to God I had let them share the search, ...    HPL\n",
      "8694   id08640  No, he said hastily, as the question was put t...    HPL\n",
      "13917  id13217  And thus the ill starred girl died a victim to...    MWS\n",
      "\n",
      "[979 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch\n",
    "\n",
    "df = pd.read_csv('homework2_data.csv', sep = ',')\n",
    "# df = df.sample(frac = 0.05)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cb204b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Among the others he saw Professor Warren Rice ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I saw that two of its iron angles were now acu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Cut loose, then, in high spirits, and rose gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>But, if the contest have proceeded thus far, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>My reply was ready; a reproach I deemed calcul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>1</td>\n",
       "      <td>At these times he would shew a sardonic humour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0</td>\n",
       "      <td>'Why, sir, there beant an o in the office, nei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>1</td>\n",
       "      <td>Would to God I had let them share the search, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>1</td>\n",
       "      <td>No, he said hastily, as the question was put t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>2</td>\n",
       "      <td>And thus the ill starred girl died a victim to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>979 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     author                                               text\n",
       "0         1  Among the others he saw Professor Warren Rice ...\n",
       "1         0  I saw that two of its iron angles were now acu...\n",
       "2         0  Cut loose, then, in high spirits, and rose gen...\n",
       "3         0  But, if the contest have proceeded thus far, i...\n",
       "4         2  My reply was ready; a reproach I deemed calcul...\n",
       "..      ...                                                ...\n",
       "974       1  At these times he would shew a sardonic humour...\n",
       "975       0  'Why, sir, there beant an o in the office, nei...\n",
       "976       1  Would to God I had let them share the search, ...\n",
       "977       1  No, he said hastily, as the question was put t...\n",
       "978       2  And thus the ill starred girl died a victim to...\n",
       "\n",
       "[979 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "df = df.drop(columns=['id'])\n",
    "\n",
    "categorial_features = ['author']\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "       transformers=[\n",
    "           ('ordinal', OrdinalEncoder(), categorial_features)\n",
    "       ],\n",
    "       remainder='passthrough',\n",
    "       verbose_feature_names_out=False\n",
    "   )\n",
    "\n",
    "encoded = ct.fit_transform(df)\n",
    "df = pd.DataFrame(encoded, columns=ct.get_feature_names_out())\n",
    "df['author'] = df['author'].astype(int)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78a3fa45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author\n",
      "0    427\n",
      "2    288\n",
      "1    264\n",
      "Name: count, dtype: int64\n",
      "min class size = 264\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class_column = 'author'\n",
    "print(df[class_column].value_counts())\n",
    "min_size = df[class_column].value_counts().min()\n",
    "\n",
    "print('min class size =', min_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "933a9dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     author                                               text\n",
      "0         1   Yog Sothoth is the key and guardian of the gate.\n",
      "1         1  He was alive, and with open, staring eyes, but...\n",
      "2         1  Mebbe ye'd like to a ben me in them days, when...\n",
      "3         1  The centuried, tottering houses on both sides ...\n",
      "4         1  It is only the inferior thinker who hastens to...\n",
      "..      ...                                                ...\n",
      "787       2                     I awoke from disturbed dreams.\n",
      "788       2  It moved slowly, but it enlightened my path, a...\n",
      "789       2  The stars came out, shedding their ineffectual...\n",
      "790       2  The landlady met her in the passage; the poor ...\n",
      "791       2  The arts of life, and the discoveries of scien...\n",
      "\n",
      "[792 rows x 2 columns]\n",
      "author\n",
      "1    264\n",
      "0    264\n",
      "2    264\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_downsampled = pd.DataFrame()\n",
    "for class_type in pd.unique(df[class_column].values):\n",
    "    sampled_class_df = df[df[class_column] == class_type].sample(min_size, random_state=777)\n",
    "    df_downsampled = pd.concat([df_downsampled, sampled_class_df], ignore_index=True)\n",
    "df_downsampled = df_downsampled[df_downsampled[class_column].notnull()]\n",
    "df_downsampled = df_downsampled[df_downsampled['text'].notnull()]\n",
    "print(df_downsampled)\n",
    "print(df_downsampled[class_column].value_counts())\n",
    "df = df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71caac0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 633 (79.9%)\n",
      "Test set size: 159 (20.1%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Шаг 2: Разделение данных на train/test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'].values,\n",
    "    df['author'].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df['author']  # для сохранения пропорций классов\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)} ({len(X_train)/len(df)*100:.1f}%)\")\n",
    "print(f\"Test set size: {len(X_test)} ({len(X_test)/len(df)*100:.1f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e92f024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f912f1fa1c74172ba0f8bd2ed164ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/197 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRobertaModel LOAD REPORT\u001b[0m from: roberta-base\n",
      "Key                             | Status     | \n",
      "--------------------------------+------------+-\n",
      "lm_head.layer_norm.weight       | UNEXPECTED | \n",
      "lm_head.dense.weight            | UNEXPECTED | \n",
      "roberta.embeddings.position_ids | UNEXPECTED | \n",
      "lm_head.bias                    | UNEXPECTED | \n",
      "lm_head.layer_norm.bias         | UNEXPECTED | \n",
      "lm_head.dense.bias              | UNEXPECTED | \n",
      "pooler.dense.bias               | MISSING    | \n",
      "pooler.dense.weight             | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Шаг 3: Инициализация токенизатора и модели BERT\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "bert_model = RobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "# Перевод модели в режим оценки (отключение dropout и т.д.)\n",
    "bert_model.eval()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bert_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99658e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_bert_embeddings(texts, batch_size=8):\n",
    "    embeddings = []\n",
    "    \n",
    "    # Внешний прогресс-бар для текстов\n",
    "    with tqdm(total=len(texts), desc=\"Всего текстов\", position=0) as pbar_texts:\n",
    "        # Внутренний прогресс-бар для батчей\n",
    "        with tqdm(total=(len(texts) + batch_size - 1) // batch_size, \n",
    "                  desc=\"Батчи\", position=1, leave=False) as pbar_batches:\n",
    "            \n",
    "            for i in range(0, len(texts), batch_size):\n",
    "                batch_texts = texts[i:i + batch_size]\n",
    "                actual_size = len(batch_texts)\n",
    "                \n",
    "                encoded = tokenizer(\n",
    "                    batch_texts.tolist() if isinstance(batch_texts, np.ndarray) else batch_texts,\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=512,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                \n",
    "                encoded = {key: val.to(device) for key, val in encoded.items()}\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs = bert_model(**encoded)\n",
    "                    cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "                    embeddings.append(cls_embeddings)\n",
    "                \n",
    "                pbar_texts.update(actual_size)\n",
    "                pbar_batches.update(1)\n",
    "    \n",
    "    return np.vstack(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f536c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "BERT + ДОПОЛНИТЕЛЬНЫЕ ПРИЗНАКИ\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Всего текстов: 100%|██████████| 633/633 [00:24<00:00, 26.03it/s]\n",
      "Всего текстов: 100%|██████████| 159/159 [00:06<00:00, 25.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT размерность: 768\n",
      "Дополнительные признаки: 6\n",
      "Итоговая размерность: 774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_additional_features(texts):\n",
    "    \"\"\"Извлекаем дополнительные признаки\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text_str = str(text)\n",
    "        \n",
    "        feat = {\n",
    "            'length': len(text_str),  # Длина текста\n",
    "            'word_count': len(text_str.split()),  # Количество слов\n",
    "            'avg_word_length': np.mean([len(w) for w in text_str.split()]) if text_str.split() else 0,\n",
    "        }\n",
    "        features.append(list(feat.values()))\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"BERT + ДОПОЛНИТЕЛЬНЫЕ ПРИЗНАКИ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Получаем BERT эмбеддинги\n",
    "X_train_bert = get_bert_embeddings(X_train)\n",
    "X_test_bert = get_bert_embeddings(X_test)\n",
    "\n",
    "# Добавляем дополнительные признаки\n",
    "X_train_extra = extract_additional_features(X_train)\n",
    "X_test_extra = extract_additional_features(X_test)\n",
    "\n",
    "# Объединяем\n",
    "X_train_embeddings = np.hstack([X_train_bert, X_train_extra])\n",
    "X_test_embeddings = np.hstack([X_test_bert, X_test_extra])\n",
    "\n",
    "print(f\"BERT размерность: {X_train_bert.shape[1]}\")\n",
    "print(f\"Дополнительные признаки: {X_train_extra.shape[1]}\")\n",
    "print(f\"Итоговая размерность: {X_train_embeddings.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "725d71dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность эмбеддингов: 774\n",
      "Проверка меток классов:\n",
      "Тип y_train: <class 'numpy.ndarray'>\n",
      "Dtype y_train: int64\n",
      "Первые 10 элементов y_train: [0 1 2 1 0 1 2 0 1 1]\n",
      "Уникальные значения: [0 1 2]\n",
      "Количество классов: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Размерность эмбеддингов: {X_train_embeddings.shape[1]}\")\n",
    "\n",
    "print(\"Проверка меток классов:\")\n",
    "print(f\"Тип y_train: {type(y_train)}\")\n",
    "print(f\"Dtype y_train: {y_train.dtype if hasattr(y_train, 'dtype') else 'N/A'}\")\n",
    "print(f\"Первые 10 элементов y_train: {y_train[:10]}\")\n",
    "print(f\"Уникальные значения: {np.unique(y_train)}\")\n",
    "print(f\"Количество классов: {len(np.unique(y_train))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "728352ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "XGBOOST КЛАССИФИКАТОР\n",
      "==================================================\n",
      "\n",
      "F1-score (XGBoost): 0.6917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.65        53\n",
      "           1       0.73      0.72      0.72        53\n",
      "           2       0.69      0.72      0.70        53\n",
      "\n",
      "    accuracy                           0.69       159\n",
      "   macro avg       0.69      0.69      0.69       159\n",
      "weighted avg       0.69      0.69      0.69       159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# print(\"=\"*50)\n",
    "# print(\"БЫСТРЫЙ GRID SEARCH ДЛЯ XGBOOST\")\n",
    "# print(\"=\"*50)\n",
    "\n",
    "# param_grid_quick = {\n",
    "#     'n_estimators': [200, 300],\n",
    "#     'max_depth': [5, 7, 9],\n",
    "#     'learning_rate': [0.05, 0.1],\n",
    "#     'subsample': [0.8, 1.0],\n",
    "#     'colsample_bytree': [0.8, 1.0],\n",
    "# }\n",
    "\n",
    "# print(f\"Комбинаций: {2*3*2*2*2} = 48\")\n",
    "# print(f\"С CV=3: 144 обучений\\n\")\n",
    "\n",
    "# xgb = XGBClassifier(\n",
    "#     random_state=42,\n",
    "#     n_jobs=4,\n",
    "#     eval_metric='mlogloss',\n",
    "#     verbosity=3\n",
    "# )\n",
    "\n",
    "# cv_strategy = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=xgb,\n",
    "#     param_grid=param_grid_quick,\n",
    "#     cv=cv_strategy,\n",
    "#     scoring='f1_weighted',\n",
    "#     scoring='f1_weighted',\n",
    "#     n_jobs=4,\n",
    "#     verbose=3  # Показывать прогресс\n",
    "# )\n",
    "\n",
    "# print(\"\\n\" + \"=\"*50)\n",
    "# print(\"ЛУЧШИЕ ПАРАМЕТРЫ\")\n",
    "# print(\"=\"*50)\n",
    "# for key, value in grid_search.best_params_.items():\n",
    "#     print(f\"  {key}: {value}\")\n",
    "\n",
    "# grid_search.fit(X_train_embeddings, y_train)\n",
    "\n",
    "\n",
    "# pip install xgboost\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"XGBOOST КЛАССИФИКАТОР\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=4,\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "\n",
    "xgb_clf.fit(X_train_embeddings, y_train)\n",
    "y_pred = xgb_clf.predict(X_test_embeddings)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"\\nF1-score (XGBoost): {f1:.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "667a8080",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_clf.predict(X_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cee90a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "РЕЗУЛЬТАТЫ\n",
      "==================================================\n",
      "\n",
      "F1-score (macro):    0.6917\n",
      "F1-score (micro):    0.6918\n",
      "F1-score (weighted): 0.6917\n",
      "\n",
      "==================================================\n",
      "ДЕТАЛЬНЫЙ ОТЧЕТ ПО КЛАССАМ\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.65        53\n",
      "           1       0.73      0.72      0.72        53\n",
      "           2       0.69      0.72      0.70        53\n",
      "\n",
      "    accuracy                           0.69       159\n",
      "   macro avg       0.69      0.69      0.69       159\n",
      "weighted avg       0.69      0.69      0.69       159\n",
      "\n",
      "\n",
      "Точность на обучающей выборке: 1.0\n",
      "Точность на тестовой выборке: 0.6918238993710691\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Шаг 8: Вычисление метрик\n",
    "# F1-score для многоклассовой классификации\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"РЕЗУЛЬТАТЫ\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nF1-score (macro):    {f1_macro:.4f}\")\n",
    "print(f\"F1-score (micro):    {f1_micro:.4f}\")\n",
    "print(f\"F1-score (weighted): {f1_weighted:.4f}\")\n",
    "\n",
    "# Детальный отчет по классам\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ДЕТАЛЬНЫЙ ОТЧЕТ ПО КЛАССАМ\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Дополнительно: важность признаков\n",
    "print(\"\\nТочность на обучающей выборке:\", xgb_clf.score(X_train_embeddings, y_train))\n",
    "print(\"Точность на тестовой выборке:\", xgb_clf.score(X_test_embeddings, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
