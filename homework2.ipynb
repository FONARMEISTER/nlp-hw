{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "446e5643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id                                               text author\n",
      "0      id26305  This process, however, afforded me no means of...    EAP\n",
      "1      id17569  It never once occurred to me that the fumbling...    HPL\n",
      "2      id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
      "3      id27763  How lovely is spring As we looked from Windsor...    MWS\n",
      "4      id12958  Finding nothing else, not even gold, the Super...    HPL\n",
      "...        ...                                                ...    ...\n",
      "19574  id17718  I could have fancied, while I looked at it, th...    EAP\n",
      "19575  id08973  The lids clenched themselves together as if in...    EAP\n",
      "19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP\n",
      "19577  id17513  For an item of news like this, it strikes us i...    EAP\n",
      "19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL\n",
      "\n",
      "[19579 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch\n",
    "\n",
    "df = pd.read_csv('homework2_data.csv', sep = ',')\n",
    "# df = df.sample(frac = 0.05)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cb204b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>0</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>0</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>0</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>0</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>1</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19579 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       author                                               text\n",
       "0           0  This process, however, afforded me no means of...\n",
       "1           1  It never once occurred to me that the fumbling...\n",
       "2           0  In his left hand was a gold snuff box, from wh...\n",
       "3           2  How lovely is spring As we looked from Windsor...\n",
       "4           1  Finding nothing else, not even gold, the Super...\n",
       "...       ...                                                ...\n",
       "19574       0  I could have fancied, while I looked at it, th...\n",
       "19575       0  The lids clenched themselves together as if in...\n",
       "19576       0  Mais il faut agir that is to say, a Frenchman ...\n",
       "19577       0  For an item of news like this, it strikes us i...\n",
       "19578       1  He laid a gnarled claw on my shoulder, and it ...\n",
       "\n",
       "[19579 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "df = df.drop(columns=['id'])\n",
    "\n",
    "categorial_features = ['author']\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "       transformers=[\n",
    "           ('ordinal', OrdinalEncoder(), categorial_features)\n",
    "       ],\n",
    "       remainder='passthrough',\n",
    "       verbose_feature_names_out=False\n",
    "   )\n",
    "\n",
    "encoded = ct.fit_transform(df)\n",
    "df = pd.DataFrame(encoded, columns=ct.get_feature_names_out())\n",
    "df['author'] = df['author'].astype(int)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78a3fa45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author\n",
      "0    7900\n",
      "2    6044\n",
      "1    5635\n",
      "Name: count, dtype: int64\n",
      "min class size = 5635\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class_column = 'author'\n",
    "print(df[class_column].value_counts())\n",
    "min_size = df[class_column].value_counts().min()\n",
    "\n",
    "print('min class size =', min_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "933a9dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       author                                               text\n",
      "0           0  Is sure that it was not the voice of an Englis...\n",
      "1           0  Meantime, our vegetation had perceptibly alter...\n",
      "2           0               \"Be a little more explicit,\" I said.\n",
      "3           0  Yet, for some minutes longer I refrained and s...\n",
      "4           0  Stay here to night, and I will send Jup down f...\n",
      "...       ...                                                ...\n",
      "16900       2  As a child I had not been content with the res...\n",
      "16901       2  I trod air; no doubt, no fear, no hope even, d...\n",
      "16902       2  A few words from us decided him, and hope and ...\n",
      "16903       2  She did not in the least resemble either of he...\n",
      "16904       2  The veil must be thicker than that invented by...\n",
      "\n",
      "[16905 rows x 2 columns]\n",
      "author\n",
      "0    5635\n",
      "1    5635\n",
      "2    5635\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_downsampled = pd.DataFrame()\n",
    "for class_type in pd.unique(df[class_column].values):\n",
    "    sampled_class_df = df[df[class_column] == class_type].sample(min_size, random_state=777)\n",
    "    df_downsampled = pd.concat([df_downsampled, sampled_class_df], ignore_index=True)\n",
    "df_downsampled = df_downsampled[df_downsampled[class_column].notnull()]\n",
    "df_downsampled = df_downsampled[df_downsampled['text'].notnull()]\n",
    "print(df_downsampled)\n",
    "print(df_downsampled[class_column].value_counts())\n",
    "df = df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71caac0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 13524 (80.0%)\n",
      "Test set size: 3381 (20.0%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Шаг 2: Разделение данных на train/test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'].values,\n",
    "    df['author'].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df['author']  # для сохранения пропорций классов\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)} ({len(X_train)/len(df)*100:.1f}%)\")\n",
    "print(f\"Test set size: {len(X_test)} ({len(X_test)/len(df)*100:.1f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e92f024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4782f0cc038404f96e75cc4db13b79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/197 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRobertaModel LOAD REPORT\u001b[0m from: roberta-base\n",
      "Key                             | Status     | \n",
      "--------------------------------+------------+-\n",
      "lm_head.layer_norm.weight       | UNEXPECTED | \n",
      "lm_head.dense.weight            | UNEXPECTED | \n",
      "roberta.embeddings.position_ids | UNEXPECTED | \n",
      "lm_head.bias                    | UNEXPECTED | \n",
      "lm_head.layer_norm.bias         | UNEXPECTED | \n",
      "lm_head.dense.bias              | UNEXPECTED | \n",
      "pooler.dense.bias               | MISSING    | \n",
      "pooler.dense.weight             | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Шаг 3: Инициализация токенизатора и модели BERT\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "bert_model = RobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "# Перевод модели в режим оценки (отключение dropout и т.д.)\n",
    "bert_model.eval()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bert_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99658e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_bert_embeddings(texts, batch_size=8):\n",
    "    embeddings = []\n",
    "    \n",
    "    # Внешний прогресс-бар для текстов\n",
    "    with tqdm(total=len(texts), desc=\"Всего текстов\", position=0) as pbar_texts:\n",
    "        # Внутренний прогресс-бар для батчей\n",
    "        with tqdm(total=(len(texts) + batch_size - 1) // batch_size, \n",
    "                  desc=\"Батчи\", position=1, leave=False) as pbar_batches:\n",
    "            \n",
    "            for i in range(0, len(texts), batch_size):\n",
    "                batch_texts = texts[i:i + batch_size]\n",
    "                actual_size = len(batch_texts)\n",
    "                \n",
    "                encoded = tokenizer(\n",
    "                    batch_texts.tolist() if isinstance(batch_texts, np.ndarray) else batch_texts,\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=512,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                \n",
    "                encoded = {key: val.to(device) for key, val in encoded.items()}\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs = bert_model(**encoded)\n",
    "                    cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "                    embeddings.append(cls_embeddings)\n",
    "                \n",
    "                pbar_texts.update(actual_size)\n",
    "                pbar_batches.update(1)\n",
    "    \n",
    "    return np.vstack(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2f536c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "BERT + ДОПОЛНИТЕЛЬНЫЕ ПРИЗНАКИ\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Всего текстов: 100%|██████████| 13524/13524 [10:24<00:00, 21.65it/s]\n",
      "Всего текстов: 100%|██████████| 3381/3381 [02:46<00:00, 20.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT размерность: 768\n",
      "Дополнительные признаки: 3\n",
      "Итоговая размерность: 771\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_additional_features(texts):\n",
    "    \"\"\"Извлекаем дополнительные признаки\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text_str = str(text)\n",
    "        \n",
    "        feat = {\n",
    "            'length': len(text_str),  # Длина текста\n",
    "            'word_count': len(text_str.split()),  # Количество слов\n",
    "            'avg_word_length': np.mean([len(w) for w in text_str.split()]) if text_str.split() else 0,\n",
    "        }\n",
    "        features.append(list(feat.values()))\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"BERT + ДОПОЛНИТЕЛЬНЫЕ ПРИЗНАКИ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Получаем BERT эмбеддинги\n",
    "X_train_bert = get_bert_embeddings(X_train)\n",
    "X_test_bert = get_bert_embeddings(X_test)\n",
    "\n",
    "# Добавляем дополнительные признаки\n",
    "X_train_extra = extract_additional_features(X_train)\n",
    "X_test_extra = extract_additional_features(X_test)\n",
    "\n",
    "# Объединяем\n",
    "X_train_embeddings = np.hstack([X_train_bert, X_train_extra])\n",
    "X_test_embeddings = np.hstack([X_test_bert, X_test_extra])\n",
    "\n",
    "print(f\"BERT размерность: {X_train_bert.shape[1]}\")\n",
    "print(f\"Дополнительные признаки: {X_train_extra.shape[1]}\")\n",
    "print(f\"Итоговая размерность: {X_train_embeddings.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "725d71dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность эмбеддингов: 771\n",
      "Проверка меток классов:\n",
      "Тип y_train: <class 'numpy.ndarray'>\n",
      "Dtype y_train: int64\n",
      "Первые 10 элементов y_train: [2 1 0 0 2 0 0 1 2 1]\n",
      "Уникальные значения: [0 1 2]\n",
      "Количество классов: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Размерность эмбеддингов: {X_train_embeddings.shape[1]}\")\n",
    "\n",
    "print(\"Проверка меток классов:\")\n",
    "print(f\"Тип y_train: {type(y_train)}\")\n",
    "print(f\"Dtype y_train: {y_train.dtype if hasattr(y_train, 'dtype') else 'N/A'}\")\n",
    "print(f\"Первые 10 элементов y_train: {y_train[:10]}\")\n",
    "print(f\"Уникальные значения: {np.unique(y_train)}\")\n",
    "print(f\"Количество классов: {len(np.unique(y_train))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "728352ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "XGBOOST КЛАССИФИКАТОР\n",
      "==================================================\n",
      "\n",
      "F1-score (XGBoost): 0.7739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74      1127\n",
      "           1       0.79      0.80      0.80      1127\n",
      "           2       0.77      0.81      0.79      1127\n",
      "\n",
      "    accuracy                           0.77      3381\n",
      "   macro avg       0.77      0.77      0.77      3381\n",
      "weighted avg       0.77      0.77      0.77      3381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# print(\"=\"*50)\n",
    "# print(\"БЫСТРЫЙ GRID SEARCH ДЛЯ XGBOOST\")\n",
    "# print(\"=\"*50)\n",
    "\n",
    "# param_grid_quick = {\n",
    "#     'n_estimators': [200, 300],\n",
    "#     'max_depth': [5, 7, 9],\n",
    "#     'learning_rate': [0.05, 0.1],\n",
    "#     'subsample': [0.8, 1.0],\n",
    "#     'colsample_bytree': [0.8, 1.0],\n",
    "# }\n",
    "\n",
    "# print(f\"Комбинаций: {2*3*2*2*2} = 48\")\n",
    "# print(f\"С CV=3: 144 обучений\\n\")\n",
    "\n",
    "# xgb = XGBClassifier(\n",
    "#     random_state=42,\n",
    "#     n_jobs=4,\n",
    "#     eval_metric='mlogloss',\n",
    "#     verbosity=3\n",
    "# )\n",
    "\n",
    "# cv_strategy = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=xgb,\n",
    "#     param_grid=param_grid_quick,\n",
    "#     cv=cv_strategy,\n",
    "#     scoring='f1_weighted',\n",
    "#     scoring='f1_weighted',\n",
    "#     n_jobs=4,\n",
    "#     verbose=3  # Показывать прогресс\n",
    "# )\n",
    "\n",
    "# print(\"\\n\" + \"=\"*50)\n",
    "# print(\"ЛУЧШИЕ ПАРАМЕТРЫ\")\n",
    "# print(\"=\"*50)\n",
    "# for key, value in grid_search.best_params_.items():\n",
    "#     print(f\"  {key}: {value}\")\n",
    "\n",
    "# grid_search.fit(X_train_embeddings, y_train)\n",
    "\n",
    "\n",
    "# pip install xgboost\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"XGBOOST КЛАССИФИКАТОР\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=4,\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "\n",
    "xgb_clf.fit(X_train_embeddings, y_train)\n",
    "y_pred = xgb_clf.predict(X_test_embeddings)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"\\nF1-score (XGBoost): {f1:.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "667a8080",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_clf.predict(X_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cee90a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "РЕЗУЛЬТАТЫ\n",
      "==================================================\n",
      "\n",
      "F1-score (macro):    0.7739\n",
      "F1-score (micro):    0.7743\n",
      "F1-score (weighted): 0.7739\n",
      "\n",
      "==================================================\n",
      "ДЕТАЛЬНЫЙ ОТЧЕТ ПО КЛАССАМ\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74      1127\n",
      "           1       0.79      0.80      0.80      1127\n",
      "           2       0.77      0.81      0.79      1127\n",
      "\n",
      "    accuracy                           0.77      3381\n",
      "   macro avg       0.77      0.77      0.77      3381\n",
      "weighted avg       0.77      0.77      0.77      3381\n",
      "\n",
      "\n",
      "Точность на обучающей выборке: 0.9990387459331559\n",
      "Точность на тестовой выборке: 0.7743271221532091\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Шаг 8: Вычисление метрик\n",
    "# F1-score для многоклассовой классификации\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"РЕЗУЛЬТАТЫ\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nF1-score (macro):    {f1_macro:.4f}\")\n",
    "print(f\"F1-score (micro):    {f1_micro:.4f}\")\n",
    "print(f\"F1-score (weighted): {f1_weighted:.4f}\")\n",
    "\n",
    "# Детальный отчет по классам\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ДЕТАЛЬНЫЙ ОТЧЕТ ПО КЛАССАМ\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Дополнительно: важность признаков\n",
    "print(\"\\nТочность на обучающей выборке:\", xgb_clf.score(X_train_embeddings, y_train))\n",
    "print(\"Точность на тестовой выборке:\", xgb_clf.score(X_test_embeddings, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
